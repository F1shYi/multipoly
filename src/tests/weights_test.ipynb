{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights test\n",
    "\n",
    "This notebook is used for testing whether we have loaded the weights of polyffusion successfully from the polyffusion checkpoints.\n",
    "\n",
    "Code scripts here can be used for partially loading the weights of polyffusion modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name : sdf_chd8bar\n",
      "batch_size : 16\n",
      "max_epoch : 100\n",
      "learning_rate : 5e-05\n",
      "max_grad_norm : 10\n",
      "fp16 : True\n",
      "num_workers : 4\n",
      "pin_memory : True\n",
      "in_channels : 2\n",
      "out_channels : 2\n",
      "channels : 64\n",
      "attention_levels : [2, 3]\n",
      "n_res_blocks : 2\n",
      "channel_multipliers : [1, 2, 4, 4]\n",
      "n_heads : 4\n",
      "tf_layers : 1\n",
      "d_cond : 512\n",
      "linear_start : 0.00085\n",
      "linear_end : 0.012\n",
      "n_steps : 1000\n",
      "latent_scaling_factor : 0.18215\n",
      "img_h : 128\n",
      "img_w : 128\n",
      "cond_type : chord\n",
      "cond_mode : mix\n",
      "use_enc : True\n",
      "chd_n_step : 32\n",
      "chd_input_dim : 36\n",
      "chd_z_input_dim : 512\n",
      "chd_hidden_dim : 512\n",
      "chd_z_dim : 512\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "MULTIPOLY_FOLDER = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "POLYFFUSION_CKPT_PATH = os.path.join(MULTIPOLY_FOLDER, r\"polyffusion_ckpts\\ldm_chd8bar\\sdf+pop909wm_mix16_chd8bar\\01-11_102022\\chkpts\\weights_best.pt\")\n",
    "POLYFFUSION_PARAMS_PATH = os.path.join(MULTIPOLY_FOLDER, r\"polyffusion_ckpts\\ldm_chd8bar\\sdf+pop909wm_mix16_chd8bar\\01-11_102022\\params.yaml\")\n",
    "CHORD_CKPT_PATH = os.path.join(MULTIPOLY_FOLDER, r\"pretrained\\chd8bar\\weights.pt\")\n",
    "\n",
    "with open(POLYFFUSION_PARAMS_PATH, 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "for key,value in params.items():\n",
    "    print(key,\":\",value)\n",
    "\n",
    "polyffusion_checkpoint = torch.load(POLYFFUSION_CKPT_PATH)[\"model\"]\n",
    "chord_checkpoint = torch.load(CHORD_CKPT_PATH)[\"model\"]\n",
    "\n",
    "sys.path.append(MULTIPOLY_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla\n",
    "\n",
    "Load the weights into the vanilla polyffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define models according to the settings in `polyffusion_ckpts\\...\\params.yaml`\n",
    "from polyffusion.dl_modules import ChordEncoder, ChordDecoder\n",
    "from polyffusion.stable_diffusion.model.unet import UNetModel\n",
    "from polyffusion.stable_diffusion.latent_diffusion import LatentDiffusion\n",
    "from polyffusion.models.model_sdf import Polyffusion_SDF\n",
    "\n",
    "import inspect\n",
    "\n",
    "chord_enc_params = inspect.signature(ChordEncoder.__init__).parameters\n",
    "chord_enc_params_dict = {key.removeprefix(\"chd_\"):params[key] for key in params if key.removeprefix(\"chd_\") in chord_enc_params}\n",
    "chord_encoder_poly = ChordEncoder(**chord_enc_params_dict)\n",
    "\n",
    "chord_dec_params = inspect.signature(ChordDecoder.__init__).parameters\n",
    "chord_dec_params_dict = {key.removeprefix(\"chd_\"):params[key] for key in params if key.removeprefix(\"chd_\") in chord_dec_params}\n",
    "chord_decoder_poly = ChordDecoder(**chord_dec_params_dict)\n",
    "\n",
    "unet_params = inspect.signature(UNetModel.__init__).parameters\n",
    "unet_params_dict = {key:params[key] for key in params if key in unet_params}\n",
    "unet_poly = UNetModel(**unet_params_dict)\n",
    "\n",
    "ldm_params = inspect.signature(LatentDiffusion.__init__).parameters\n",
    "ldm_params_dict = {key:params[key] for key in params if key in ldm_params}\n",
    "ldm_poly = LatentDiffusion(unet_model=unet_poly, autoencoder=None, **ldm_params_dict)\n",
    "\n",
    "\n",
    "polyffusion_params = inspect.signature(Polyffusion_SDF.__init__).parameters\n",
    "polyffusion_params_dict = {key:params[key] for key in params if key in polyffusion_params}\n",
    "polyffusion = Polyffusion_SDF(ldm=ldm_poly,chord_enc=chord_encoder_poly,chord_dec=chord_decoder_poly,**polyffusion_params_dict)\n",
    "\n",
    "polyffusion.load_state_dict(polyffusion_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet only\n",
    "\n",
    "Load the UNet weights only. Check if the UNet weights equal to the `eps_model` in the vanilla polyffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet_only = UNetModel(**unet_params_dict)\n",
    "UNET_PREFIX = \"ldm.eps_model.\"\n",
    "unet_state_dict = {key.removeprefix(UNET_PREFIX):value for key,value in polyffusion_checkpoint.items() if key.startswith(UNET_PREFIX)}\n",
    "unet_only.load_state_dict(unet_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_embed.0.weight\n",
      "time_embed.0.bias\n",
      "time_embed.2.weight\n",
      "time_embed.2.bias\n",
      "input_blocks.0.0.weight\n",
      "input_blocks.0.0.bias\n",
      "input_blocks.1.0.in_layers.0.weight\n",
      "input_blocks.1.0.in_layers.0.bias\n",
      "input_blocks.1.0.in_layers.2.weight\n",
      "input_blocks.1.0.in_layers.2.bias\n",
      "input_blocks.1.0.emb_layers.1.weight\n",
      "input_blocks.1.0.emb_layers.1.bias\n",
      "input_blocks.1.0.out_layers.0.weight\n",
      "input_blocks.1.0.out_layers.0.bias\n",
      "input_blocks.1.0.out_layers.3.weight\n",
      "input_blocks.1.0.out_layers.3.bias\n",
      "input_blocks.2.0.in_layers.0.weight\n",
      "input_blocks.2.0.in_layers.0.bias\n",
      "input_blocks.2.0.in_layers.2.weight\n",
      "input_blocks.2.0.in_layers.2.bias\n",
      "input_blocks.2.0.emb_layers.1.weight\n",
      "input_blocks.2.0.emb_layers.1.bias\n",
      "input_blocks.2.0.out_layers.0.weight\n",
      "input_blocks.2.0.out_layers.0.bias\n",
      "input_blocks.2.0.out_layers.3.weight\n",
      "input_blocks.2.0.out_layers.3.bias\n",
      "input_blocks.3.0.op.weight\n",
      "input_blocks.3.0.op.bias\n",
      "input_blocks.4.0.in_layers.0.weight\n",
      "input_blocks.4.0.in_layers.0.bias\n",
      "input_blocks.4.0.in_layers.2.weight\n",
      "input_blocks.4.0.in_layers.2.bias\n",
      "input_blocks.4.0.emb_layers.1.weight\n",
      "input_blocks.4.0.emb_layers.1.bias\n",
      "input_blocks.4.0.out_layers.0.weight\n",
      "input_blocks.4.0.out_layers.0.bias\n",
      "input_blocks.4.0.out_layers.3.weight\n",
      "input_blocks.4.0.out_layers.3.bias\n",
      "input_blocks.4.0.skip_connection.weight\n",
      "input_blocks.4.0.skip_connection.bias\n",
      "input_blocks.5.0.in_layers.0.weight\n",
      "input_blocks.5.0.in_layers.0.bias\n",
      "input_blocks.5.0.in_layers.2.weight\n",
      "input_blocks.5.0.in_layers.2.bias\n",
      "input_blocks.5.0.emb_layers.1.weight\n",
      "input_blocks.5.0.emb_layers.1.bias\n",
      "input_blocks.5.0.out_layers.0.weight\n",
      "input_blocks.5.0.out_layers.0.bias\n",
      "input_blocks.5.0.out_layers.3.weight\n",
      "input_blocks.5.0.out_layers.3.bias\n",
      "input_blocks.6.0.op.weight\n",
      "input_blocks.6.0.op.bias\n",
      "input_blocks.7.0.in_layers.0.weight\n",
      "input_blocks.7.0.in_layers.0.bias\n",
      "input_blocks.7.0.in_layers.2.weight\n",
      "input_blocks.7.0.in_layers.2.bias\n",
      "input_blocks.7.0.emb_layers.1.weight\n",
      "input_blocks.7.0.emb_layers.1.bias\n",
      "input_blocks.7.0.out_layers.0.weight\n",
      "input_blocks.7.0.out_layers.0.bias\n",
      "input_blocks.7.0.out_layers.3.weight\n",
      "input_blocks.7.0.out_layers.3.bias\n",
      "input_blocks.7.0.skip_connection.weight\n",
      "input_blocks.7.0.skip_connection.bias\n",
      "input_blocks.7.1.norm.weight\n",
      "input_blocks.7.1.norm.bias\n",
      "input_blocks.7.1.proj_in.weight\n",
      "input_blocks.7.1.proj_in.bias\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "input_blocks.7.1.transformer_blocks.0.norm1.weight\n",
      "input_blocks.7.1.transformer_blocks.0.norm1.bias\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "input_blocks.7.1.transformer_blocks.0.norm2.weight\n",
      "input_blocks.7.1.transformer_blocks.0.norm2.bias\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.2.weight\n",
      "input_blocks.7.1.transformer_blocks.0.ff.net.2.bias\n",
      "input_blocks.7.1.transformer_blocks.0.norm3.weight\n",
      "input_blocks.7.1.transformer_blocks.0.norm3.bias\n",
      "input_blocks.7.1.proj_out.weight\n",
      "input_blocks.7.1.proj_out.bias\n",
      "input_blocks.8.0.in_layers.0.weight\n",
      "input_blocks.8.0.in_layers.0.bias\n",
      "input_blocks.8.0.in_layers.2.weight\n",
      "input_blocks.8.0.in_layers.2.bias\n",
      "input_blocks.8.0.emb_layers.1.weight\n",
      "input_blocks.8.0.emb_layers.1.bias\n",
      "input_blocks.8.0.out_layers.0.weight\n",
      "input_blocks.8.0.out_layers.0.bias\n",
      "input_blocks.8.0.out_layers.3.weight\n",
      "input_blocks.8.0.out_layers.3.bias\n",
      "input_blocks.8.1.norm.weight\n",
      "input_blocks.8.1.norm.bias\n",
      "input_blocks.8.1.proj_in.weight\n",
      "input_blocks.8.1.proj_in.bias\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "input_blocks.8.1.transformer_blocks.0.norm1.weight\n",
      "input_blocks.8.1.transformer_blocks.0.norm1.bias\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "input_blocks.8.1.transformer_blocks.0.norm2.weight\n",
      "input_blocks.8.1.transformer_blocks.0.norm2.bias\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.2.weight\n",
      "input_blocks.8.1.transformer_blocks.0.ff.net.2.bias\n",
      "input_blocks.8.1.transformer_blocks.0.norm3.weight\n",
      "input_blocks.8.1.transformer_blocks.0.norm3.bias\n",
      "input_blocks.8.1.proj_out.weight\n",
      "input_blocks.8.1.proj_out.bias\n",
      "input_blocks.9.0.op.weight\n",
      "input_blocks.9.0.op.bias\n",
      "input_blocks.10.0.in_layers.0.weight\n",
      "input_blocks.10.0.in_layers.0.bias\n",
      "input_blocks.10.0.in_layers.2.weight\n",
      "input_blocks.10.0.in_layers.2.bias\n",
      "input_blocks.10.0.emb_layers.1.weight\n",
      "input_blocks.10.0.emb_layers.1.bias\n",
      "input_blocks.10.0.out_layers.0.weight\n",
      "input_blocks.10.0.out_layers.0.bias\n",
      "input_blocks.10.0.out_layers.3.weight\n",
      "input_blocks.10.0.out_layers.3.bias\n",
      "input_blocks.10.1.norm.weight\n",
      "input_blocks.10.1.norm.bias\n",
      "input_blocks.10.1.proj_in.weight\n",
      "input_blocks.10.1.proj_in.bias\n",
      "input_blocks.10.1.transformer_blocks.0.attn1.to_q.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn1.to_k.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn1.to_v.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "input_blocks.10.1.transformer_blocks.0.norm1.weight\n",
      "input_blocks.10.1.transformer_blocks.0.norm1.bias\n",
      "input_blocks.10.1.transformer_blocks.0.attn2.to_q.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn2.to_k.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn2.to_v.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "input_blocks.10.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "input_blocks.10.1.transformer_blocks.0.norm2.weight\n",
      "input_blocks.10.1.transformer_blocks.0.norm2.bias\n",
      "input_blocks.10.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "input_blocks.10.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "input_blocks.10.1.transformer_blocks.0.ff.net.2.weight\n",
      "input_blocks.10.1.transformer_blocks.0.ff.net.2.bias\n",
      "input_blocks.10.1.transformer_blocks.0.norm3.weight\n",
      "input_blocks.10.1.transformer_blocks.0.norm3.bias\n",
      "input_blocks.10.1.proj_out.weight\n",
      "input_blocks.10.1.proj_out.bias\n",
      "input_blocks.11.0.in_layers.0.weight\n",
      "input_blocks.11.0.in_layers.0.bias\n",
      "input_blocks.11.0.in_layers.2.weight\n",
      "input_blocks.11.0.in_layers.2.bias\n",
      "input_blocks.11.0.emb_layers.1.weight\n",
      "input_blocks.11.0.emb_layers.1.bias\n",
      "input_blocks.11.0.out_layers.0.weight\n",
      "input_blocks.11.0.out_layers.0.bias\n",
      "input_blocks.11.0.out_layers.3.weight\n",
      "input_blocks.11.0.out_layers.3.bias\n",
      "input_blocks.11.1.norm.weight\n",
      "input_blocks.11.1.norm.bias\n",
      "input_blocks.11.1.proj_in.weight\n",
      "input_blocks.11.1.proj_in.bias\n",
      "input_blocks.11.1.transformer_blocks.0.attn1.to_q.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn1.to_k.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn1.to_v.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "input_blocks.11.1.transformer_blocks.0.norm1.weight\n",
      "input_blocks.11.1.transformer_blocks.0.norm1.bias\n",
      "input_blocks.11.1.transformer_blocks.0.attn2.to_q.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn2.to_k.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn2.to_v.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "input_blocks.11.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "input_blocks.11.1.transformer_blocks.0.norm2.weight\n",
      "input_blocks.11.1.transformer_blocks.0.norm2.bias\n",
      "input_blocks.11.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "input_blocks.11.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "input_blocks.11.1.transformer_blocks.0.ff.net.2.weight\n",
      "input_blocks.11.1.transformer_blocks.0.ff.net.2.bias\n",
      "input_blocks.11.1.transformer_blocks.0.norm3.weight\n",
      "input_blocks.11.1.transformer_blocks.0.norm3.bias\n",
      "input_blocks.11.1.proj_out.weight\n",
      "input_blocks.11.1.proj_out.bias\n",
      "middle_block.0.in_layers.0.weight\n",
      "middle_block.0.in_layers.0.bias\n",
      "middle_block.0.in_layers.2.weight\n",
      "middle_block.0.in_layers.2.bias\n",
      "middle_block.0.emb_layers.1.weight\n",
      "middle_block.0.emb_layers.1.bias\n",
      "middle_block.0.out_layers.0.weight\n",
      "middle_block.0.out_layers.0.bias\n",
      "middle_block.0.out_layers.3.weight\n",
      "middle_block.0.out_layers.3.bias\n",
      "middle_block.1.norm.weight\n",
      "middle_block.1.norm.bias\n",
      "middle_block.1.proj_in.weight\n",
      "middle_block.1.proj_in.bias\n",
      "middle_block.1.transformer_blocks.0.attn1.to_q.weight\n",
      "middle_block.1.transformer_blocks.0.attn1.to_k.weight\n",
      "middle_block.1.transformer_blocks.0.attn1.to_v.weight\n",
      "middle_block.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "middle_block.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "middle_block.1.transformer_blocks.0.norm1.weight\n",
      "middle_block.1.transformer_blocks.0.norm1.bias\n",
      "middle_block.1.transformer_blocks.0.attn2.to_q.weight\n",
      "middle_block.1.transformer_blocks.0.attn2.to_k.weight\n",
      "middle_block.1.transformer_blocks.0.attn2.to_v.weight\n",
      "middle_block.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "middle_block.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "middle_block.1.transformer_blocks.0.norm2.weight\n",
      "middle_block.1.transformer_blocks.0.norm2.bias\n",
      "middle_block.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "middle_block.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "middle_block.1.transformer_blocks.0.ff.net.2.weight\n",
      "middle_block.1.transformer_blocks.0.ff.net.2.bias\n",
      "middle_block.1.transformer_blocks.0.norm3.weight\n",
      "middle_block.1.transformer_blocks.0.norm3.bias\n",
      "middle_block.1.proj_out.weight\n",
      "middle_block.1.proj_out.bias\n",
      "middle_block.2.in_layers.0.weight\n",
      "middle_block.2.in_layers.0.bias\n",
      "middle_block.2.in_layers.2.weight\n",
      "middle_block.2.in_layers.2.bias\n",
      "middle_block.2.emb_layers.1.weight\n",
      "middle_block.2.emb_layers.1.bias\n",
      "middle_block.2.out_layers.0.weight\n",
      "middle_block.2.out_layers.0.bias\n",
      "middle_block.2.out_layers.3.weight\n",
      "middle_block.2.out_layers.3.bias\n",
      "output_blocks.0.0.in_layers.0.weight\n",
      "output_blocks.0.0.in_layers.0.bias\n",
      "output_blocks.0.0.in_layers.2.weight\n",
      "output_blocks.0.0.in_layers.2.bias\n",
      "output_blocks.0.0.emb_layers.1.weight\n",
      "output_blocks.0.0.emb_layers.1.bias\n",
      "output_blocks.0.0.out_layers.0.weight\n",
      "output_blocks.0.0.out_layers.0.bias\n",
      "output_blocks.0.0.out_layers.3.weight\n",
      "output_blocks.0.0.out_layers.3.bias\n",
      "output_blocks.0.0.skip_connection.weight\n",
      "output_blocks.0.0.skip_connection.bias\n",
      "output_blocks.0.1.norm.weight\n",
      "output_blocks.0.1.norm.bias\n",
      "output_blocks.0.1.proj_in.weight\n",
      "output_blocks.0.1.proj_in.bias\n",
      "output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.0.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.0.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.0.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.0.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.0.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.0.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.0.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.0.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.0.1.proj_out.weight\n",
      "output_blocks.0.1.proj_out.bias\n",
      "output_blocks.1.0.in_layers.0.weight\n",
      "output_blocks.1.0.in_layers.0.bias\n",
      "output_blocks.1.0.in_layers.2.weight\n",
      "output_blocks.1.0.in_layers.2.bias\n",
      "output_blocks.1.0.emb_layers.1.weight\n",
      "output_blocks.1.0.emb_layers.1.bias\n",
      "output_blocks.1.0.out_layers.0.weight\n",
      "output_blocks.1.0.out_layers.0.bias\n",
      "output_blocks.1.0.out_layers.3.weight\n",
      "output_blocks.1.0.out_layers.3.bias\n",
      "output_blocks.1.0.skip_connection.weight\n",
      "output_blocks.1.0.skip_connection.bias\n",
      "output_blocks.1.1.norm.weight\n",
      "output_blocks.1.1.norm.bias\n",
      "output_blocks.1.1.proj_in.weight\n",
      "output_blocks.1.1.proj_in.bias\n",
      "output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.1.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.1.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.1.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.1.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.1.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.1.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.1.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.1.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.1.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.1.1.proj_out.weight\n",
      "output_blocks.1.1.proj_out.bias\n",
      "output_blocks.2.0.in_layers.0.weight\n",
      "output_blocks.2.0.in_layers.0.bias\n",
      "output_blocks.2.0.in_layers.2.weight\n",
      "output_blocks.2.0.in_layers.2.bias\n",
      "output_blocks.2.0.emb_layers.1.weight\n",
      "output_blocks.2.0.emb_layers.1.bias\n",
      "output_blocks.2.0.out_layers.0.weight\n",
      "output_blocks.2.0.out_layers.0.bias\n",
      "output_blocks.2.0.out_layers.3.weight\n",
      "output_blocks.2.0.out_layers.3.bias\n",
      "output_blocks.2.0.skip_connection.weight\n",
      "output_blocks.2.0.skip_connection.bias\n",
      "output_blocks.2.1.norm.weight\n",
      "output_blocks.2.1.norm.bias\n",
      "output_blocks.2.1.proj_in.weight\n",
      "output_blocks.2.1.proj_in.bias\n",
      "output_blocks.2.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.2.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.2.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.2.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.2.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.2.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.2.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.2.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.2.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.2.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.2.1.proj_out.weight\n",
      "output_blocks.2.1.proj_out.bias\n",
      "output_blocks.2.2.conv.weight\n",
      "output_blocks.2.2.conv.bias\n",
      "output_blocks.3.0.in_layers.0.weight\n",
      "output_blocks.3.0.in_layers.0.bias\n",
      "output_blocks.3.0.in_layers.2.weight\n",
      "output_blocks.3.0.in_layers.2.bias\n",
      "output_blocks.3.0.emb_layers.1.weight\n",
      "output_blocks.3.0.emb_layers.1.bias\n",
      "output_blocks.3.0.out_layers.0.weight\n",
      "output_blocks.3.0.out_layers.0.bias\n",
      "output_blocks.3.0.out_layers.3.weight\n",
      "output_blocks.3.0.out_layers.3.bias\n",
      "output_blocks.3.0.skip_connection.weight\n",
      "output_blocks.3.0.skip_connection.bias\n",
      "output_blocks.3.1.norm.weight\n",
      "output_blocks.3.1.norm.bias\n",
      "output_blocks.3.1.proj_in.weight\n",
      "output_blocks.3.1.proj_in.bias\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.3.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.3.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.3.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.3.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.3.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.3.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.3.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.3.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.3.1.proj_out.weight\n",
      "output_blocks.3.1.proj_out.bias\n",
      "output_blocks.4.0.in_layers.0.weight\n",
      "output_blocks.4.0.in_layers.0.bias\n",
      "output_blocks.4.0.in_layers.2.weight\n",
      "output_blocks.4.0.in_layers.2.bias\n",
      "output_blocks.4.0.emb_layers.1.weight\n",
      "output_blocks.4.0.emb_layers.1.bias\n",
      "output_blocks.4.0.out_layers.0.weight\n",
      "output_blocks.4.0.out_layers.0.bias\n",
      "output_blocks.4.0.out_layers.3.weight\n",
      "output_blocks.4.0.out_layers.3.bias\n",
      "output_blocks.4.0.skip_connection.weight\n",
      "output_blocks.4.0.skip_connection.bias\n",
      "output_blocks.4.1.norm.weight\n",
      "output_blocks.4.1.norm.bias\n",
      "output_blocks.4.1.proj_in.weight\n",
      "output_blocks.4.1.proj_in.bias\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.4.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.4.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.4.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.4.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.4.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.4.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.4.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.4.1.proj_out.weight\n",
      "output_blocks.4.1.proj_out.bias\n",
      "output_blocks.5.0.in_layers.0.weight\n",
      "output_blocks.5.0.in_layers.0.bias\n",
      "output_blocks.5.0.in_layers.2.weight\n",
      "output_blocks.5.0.in_layers.2.bias\n",
      "output_blocks.5.0.emb_layers.1.weight\n",
      "output_blocks.5.0.emb_layers.1.bias\n",
      "output_blocks.5.0.out_layers.0.weight\n",
      "output_blocks.5.0.out_layers.0.bias\n",
      "output_blocks.5.0.out_layers.3.weight\n",
      "output_blocks.5.0.out_layers.3.bias\n",
      "output_blocks.5.0.skip_connection.weight\n",
      "output_blocks.5.0.skip_connection.bias\n",
      "output_blocks.5.1.norm.weight\n",
      "output_blocks.5.1.norm.bias\n",
      "output_blocks.5.1.proj_in.weight\n",
      "output_blocks.5.1.proj_in.bias\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_q.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_k.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_v.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias\n",
      "output_blocks.5.1.transformer_blocks.0.norm1.weight\n",
      "output_blocks.5.1.transformer_blocks.0.norm1.bias\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_q.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_k.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_v.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight\n",
      "output_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias\n",
      "output_blocks.5.1.transformer_blocks.0.norm2.weight\n",
      "output_blocks.5.1.transformer_blocks.0.norm2.bias\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.2.weight\n",
      "output_blocks.5.1.transformer_blocks.0.ff.net.2.bias\n",
      "output_blocks.5.1.transformer_blocks.0.norm3.weight\n",
      "output_blocks.5.1.transformer_blocks.0.norm3.bias\n",
      "output_blocks.5.1.proj_out.weight\n",
      "output_blocks.5.1.proj_out.bias\n",
      "output_blocks.5.2.conv.weight\n",
      "output_blocks.5.2.conv.bias\n",
      "output_blocks.6.0.in_layers.0.weight\n",
      "output_blocks.6.0.in_layers.0.bias\n",
      "output_blocks.6.0.in_layers.2.weight\n",
      "output_blocks.6.0.in_layers.2.bias\n",
      "output_blocks.6.0.emb_layers.1.weight\n",
      "output_blocks.6.0.emb_layers.1.bias\n",
      "output_blocks.6.0.out_layers.0.weight\n",
      "output_blocks.6.0.out_layers.0.bias\n",
      "output_blocks.6.0.out_layers.3.weight\n",
      "output_blocks.6.0.out_layers.3.bias\n",
      "output_blocks.6.0.skip_connection.weight\n",
      "output_blocks.6.0.skip_connection.bias\n",
      "output_blocks.7.0.in_layers.0.weight\n",
      "output_blocks.7.0.in_layers.0.bias\n",
      "output_blocks.7.0.in_layers.2.weight\n",
      "output_blocks.7.0.in_layers.2.bias\n",
      "output_blocks.7.0.emb_layers.1.weight\n",
      "output_blocks.7.0.emb_layers.1.bias\n",
      "output_blocks.7.0.out_layers.0.weight\n",
      "output_blocks.7.0.out_layers.0.bias\n",
      "output_blocks.7.0.out_layers.3.weight\n",
      "output_blocks.7.0.out_layers.3.bias\n",
      "output_blocks.7.0.skip_connection.weight\n",
      "output_blocks.7.0.skip_connection.bias\n",
      "output_blocks.8.0.in_layers.0.weight\n",
      "output_blocks.8.0.in_layers.0.bias\n",
      "output_blocks.8.0.in_layers.2.weight\n",
      "output_blocks.8.0.in_layers.2.bias\n",
      "output_blocks.8.0.emb_layers.1.weight\n",
      "output_blocks.8.0.emb_layers.1.bias\n",
      "output_blocks.8.0.out_layers.0.weight\n",
      "output_blocks.8.0.out_layers.0.bias\n",
      "output_blocks.8.0.out_layers.3.weight\n",
      "output_blocks.8.0.out_layers.3.bias\n",
      "output_blocks.8.0.skip_connection.weight\n",
      "output_blocks.8.0.skip_connection.bias\n",
      "output_blocks.8.1.conv.weight\n",
      "output_blocks.8.1.conv.bias\n",
      "output_blocks.9.0.in_layers.0.weight\n",
      "output_blocks.9.0.in_layers.0.bias\n",
      "output_blocks.9.0.in_layers.2.weight\n",
      "output_blocks.9.0.in_layers.2.bias\n",
      "output_blocks.9.0.emb_layers.1.weight\n",
      "output_blocks.9.0.emb_layers.1.bias\n",
      "output_blocks.9.0.out_layers.0.weight\n",
      "output_blocks.9.0.out_layers.0.bias\n",
      "output_blocks.9.0.out_layers.3.weight\n",
      "output_blocks.9.0.out_layers.3.bias\n",
      "output_blocks.9.0.skip_connection.weight\n",
      "output_blocks.9.0.skip_connection.bias\n",
      "output_blocks.10.0.in_layers.0.weight\n",
      "output_blocks.10.0.in_layers.0.bias\n",
      "output_blocks.10.0.in_layers.2.weight\n",
      "output_blocks.10.0.in_layers.2.bias\n",
      "output_blocks.10.0.emb_layers.1.weight\n",
      "output_blocks.10.0.emb_layers.1.bias\n",
      "output_blocks.10.0.out_layers.0.weight\n",
      "output_blocks.10.0.out_layers.0.bias\n",
      "output_blocks.10.0.out_layers.3.weight\n",
      "output_blocks.10.0.out_layers.3.bias\n",
      "output_blocks.10.0.skip_connection.weight\n",
      "output_blocks.10.0.skip_connection.bias\n",
      "output_blocks.11.0.in_layers.0.weight\n",
      "output_blocks.11.0.in_layers.0.bias\n",
      "output_blocks.11.0.in_layers.2.weight\n",
      "output_blocks.11.0.in_layers.2.bias\n",
      "output_blocks.11.0.emb_layers.1.weight\n",
      "output_blocks.11.0.emb_layers.1.bias\n",
      "output_blocks.11.0.out_layers.0.weight\n",
      "output_blocks.11.0.out_layers.0.bias\n",
      "output_blocks.11.0.out_layers.3.weight\n",
      "output_blocks.11.0.out_layers.3.bias\n",
      "output_blocks.11.0.skip_connection.weight\n",
      "output_blocks.11.0.skip_connection.bias\n",
      "out.0.weight\n",
      "out.0.bias\n",
      "out.2.weight\n",
      "out.2.bias\n"
     ]
    }
   ],
   "source": [
    "for key in unet_only.state_dict().keys():\n",
    "    assert torch.allclose(unet_only.state_dict()[key],unet_poly.state_dict()[key])\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord VAE only\n",
    "\n",
    "Load the Chord VAE only. Check if the Chord VAE weights equal to the pretrained Chord VAE in folder `pretrained/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_encoder_only = ChordEncoder(**chord_enc_params_dict)\n",
    "CHORD_ENC_PREFIX = \"chord_enc.\"\n",
    "chord_enc_state_dict = {key.removeprefix(CHORD_ENC_PREFIX):value for key,value in chord_checkpoint.items() if key.startswith(CHORD_ENC_PREFIX)}\n",
    "chord_encoder_only.load_state_dict(chord_enc_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_decoder_only = ChordDecoder(**chord_dec_params_dict)\n",
    "CHORD_DEC_PREFIX = \"chord_dec.\"\n",
    "chord_dec_state_dict = {key.removeprefix(CHORD_DEC_PREFIX):value for key,value in chord_checkpoint.items() if key.startswith(CHORD_DEC_PREFIX)}\n",
    "chord_decoder_only.load_state_dict(chord_dec_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in chord_encoder_only.state_dict().keys():\n",
    "    assert torch.allclose(chord_encoder_only.state_dict()[key],chord_encoder_poly.state_dict()[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in chord_decoder_only.state_dict().keys():\n",
    "    assert torch.allclose(chord_decoder_only.state_dict()[key],chord_decoder_poly.state_dict()[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
